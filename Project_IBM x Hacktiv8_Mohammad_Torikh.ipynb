{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2CVr3qlhH_n"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Installations\n",
        "pip install pandas\n",
        "pip install langchain_community\n",
        "pip install replicate\n",
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1pV20WohW2e"
      },
      "outputs": [],
      "source": [
        "# Cell 2: API and Model Setup\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from langchain_community.llms import Replicate\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the API key from Colab Secrets\n",
        "try:\n",
        "    api_token = userdata.get('api_token')\n",
        "    os.environ[\"\"] = api_token\n",
        "    print(\"‚úÖ REPLICATE_API_TOKEN loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® Error loading API token: {e}\")\n",
        "    print(\"Please ensure you have a secret named 'REPLICATE_API_TOKEN' in your Colab secrets.\")\n",
        "\n",
        "# Initialize the IBM Granite model\n",
        "# This will only work if the API token was loaded correctly\n",
        "try:\n",
        "    llm = Replicate(\n",
        "      model=\"ibm-granite/granite-3.3-8b-instruct\",\n",
        "      model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 100} # Control output\n",
        "    )\n",
        "    print(\"‚úÖ IBM Granite model initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® Error initializing the model: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW72nm-yhZbC"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Load the Data\n",
        "# The URL to the raw CSV file on GitHub\n",
        "csv_url = 'https://raw.githubusercontent.com/nikjohn7/Disaster-Tweets-Kaggle/main/data/train.csv'\n",
        "\n",
        "# Read the data into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_csv(csv_url)\n",
        "    print(f\"‚úÖ Successfully loaded {len(df)} total tweets.\")\n",
        "\n",
        "    # --- CRITICAL STEP FOR SPEED ---\n",
        "    # Create a smaller sample to work with. We'll use 100 for this run.\n",
        "    sample_size = 100\n",
        "    df_sample = df.head(sample_size)\n",
        "    print(f\"üî• Created a sample of {len(df_sample)} tweets to process.\")\n",
        "\n",
        "    # Display the first 5 rows of our sample to see what we're working with\n",
        "    print(\"\\n--- Data Preview ---\")\n",
        "    print(df_sample.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"üö® Error loading data from URL: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AYRtaVoiIcb"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Part 1 - Data Classification\n",
        "# Our goal: Assign a predefined category to each tweet to structure the chaos.\n",
        "\n",
        "# Create an empty list to store our classification results\n",
        "classification_results = []\n",
        "\n",
        "# Define the classification prompt template\n",
        "prompt_template = \"\"\"\n",
        "Analyze the tweet below and classify it into ONE of the following categories:\n",
        "- 'Urgent Plea for Help': A direct request for assistance from someone in danger.\n",
        "- 'Infrastructure Damage Report': A report of damage to bridges, roads, power lines, etc.\n",
        "- 'Informational News/Update': A news link, official update, or general information.\n",
        "- 'Irrelevant/Noise': A prayer, joke, or comment not related to the disaster itself.\n",
        "\n",
        "Provide only the category name as your answer.\n",
        "\n",
        "Tweet: \"{tweet_text}\"\n",
        "\n",
        "Classification:\n",
        "\"\"\"\n",
        "\n",
        "# Use tqdm for a progress bar!\n",
        "for index, row in tqdm(df_sample.iterrows(), total=df_sample.shape[0], desc=\"Classifying Tweets\"):\n",
        "    tweet_text = row['text']\n",
        "    final_prompt = prompt_template.format(tweet_text=tweet_text)\n",
        "\n",
        "    try:\n",
        "        response = llm.invoke(final_prompt)\n",
        "        classification = response.strip()\n",
        "\n",
        "        classification_results.append({\n",
        "            'tweet_id': row['id'],\n",
        "            'tweet_text': tweet_text,\n",
        "            'classification': classification\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üö® Error classifying tweet {row['id']}: {e}\")\n",
        "        classification_results.append({\n",
        "            'tweet_id': row['id'],\n",
        "            'tweet_text': tweet_text,\n",
        "            'classification': 'ERROR'\n",
        "        })\n",
        "\n",
        "# Convert the results list into a new DataFrame for the next steps\n",
        "results_df = pd.DataFrame(classification_results)\n",
        "print(\"\\n‚úÖ Classification phase complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQhoatcnjTN2"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Analyzing the Classification Results\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"--- üìä INSIGHT FROM CLASSIFICATION ---\")\n",
        "print(\"This breakdown shows us where to focus our attention.\\n\")\n",
        "\n",
        "# Get the counts of each category\n",
        "classification_counts = results_df['classification'].value_counts()\n",
        "print(classification_counts)\n",
        "\n",
        "# --- Visualization ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=classification_counts.index, y=classification_counts.values, palette='viridis')\n",
        "plt.title('Distribution of Disaster Tweet Classifications', fontsize=16)\n",
        "plt.ylabel('Number of Tweets', fontsize=12)\n",
        "plt.xlabel('Classification Category', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFF-b03bjXPR"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Part 2 - Data Summarization\n",
        "# Our goal: Distill the most critical classified data into a high-level summary.\n",
        "\n",
        "print(\"\\n\\n--- üìù INITIATING SUMMARIZATION PHASE ---\")\n",
        "\n",
        "# First, isolate the tweets that are most important\n",
        "# We'll focus on 'Urgent Plea for Help'\n",
        "urgent_pleas_df = results_df[results_df['classification'] == 'Urgent Plea for Help']\n",
        "\n",
        "# Check if we have any urgent pleas to summarize\n",
        "if not urgent_pleas_df.empty:\n",
        "    print(f\"Found {len(urgent_pleas_df)} urgent pleas. Compiling for summary...\")\n",
        "\n",
        "    # Combine all the urgent tweets into a single block of text\n",
        "    all_pleas_text = \"\\n\".join(\"- \" + tweet for tweet in urgent_pleas_df['tweet_text'])\n",
        "\n",
        "    # Create a powerful summarization prompt\n",
        "    summarization_prompt = f\"\"\"\n",
        "You are an expert emergency services analyst. Your job is to provide a quick intelligence briefing.\n",
        "Read the following collection of urgent pleas for help from a disaster zone and provide a concise summary in 3-4 bullet points.\n",
        "Focus on identifying recurring themes, types of emergencies (e.g., trapped people, fires, injuries), and any specific locations mentioned.\n",
        "\n",
        "Urgent Tweets:\n",
        "{all_pleas_text}\n",
        "\n",
        "Intelligence Briefing:\n",
        "\"\"\"\n",
        "\n",
        "    print(\"\\nSending compiled pleas to IBM Granite for summarization...\")\n",
        "    try:\n",
        "        # Get the summary from the LLM\n",
        "        summary_response = llm.invoke(summarization_prompt)\n",
        "\n",
        "        # --- üö® FINAL KEY INSIGHT üö® ---\n",
        "        print(\"\\n\\n--- EXECUTIVE SUMMARY OF URGENT PLEAS ---\")\n",
        "        print(summary_response)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üö® Error during summarization: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo tweets were classified as 'Urgent Plea for Help' in this sample. Skipping summarization.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
