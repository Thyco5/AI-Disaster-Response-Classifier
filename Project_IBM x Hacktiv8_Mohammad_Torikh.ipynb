{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2CVr3qlhH_n"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Installations\n",
        "!pip install pandas\n",
        "!pip install langchain_community\n",
        "!pip install replicate\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: API and Model Setup (Corrected)\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_community.llms import Replicate\n",
        "\n",
        "# This is the standard and most reliable way to set the API key for LangChain\n",
        "# It directly checks for the secret and sets the environment variable.\n",
        "try:\n",
        "    os.environ['REPLICATE_API_TOKEN'] = userdata.get('REPLICATE_API_TOKEN')\n",
        "    print(\"‚úÖ REPLICATE_API_TOKEN has been set successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® CRITICAL ERROR: Could not find the secret 'REPLICATE_API_TOKEN'.\")\n",
        "    print(\"Please check the name and that notebook access is enabled.\")\n",
        "\n",
        "# Now, initialize the model. This will only work if the key was set above.\n",
        "try:\n",
        "    llm = Replicate(\n",
        "      model=\"ibm-granite/granite-3.3-8b-instruct\",\n",
        "      model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 50} # Controlling token length for classification\n",
        "    )\n",
        "    print(\"‚úÖ IBM Granite model initialized and ready.\")\n",
        "except Exception as e:\n",
        "    # This error will now clearly tell you if the key is the problem.\n",
        "    print(f\"üö® Error initializing the model: {e}\")"
      ],
      "metadata": {
        "id": "g1pV20WohW2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load the Data\n",
        "# The URL to the raw CSV file on GitHub\n",
        "csv_url = 'https://raw.githubusercontent.com/nikjohn7/Disaster-Tweets-Kaggle/main/data/train.csv'\n",
        "\n",
        "# Read the data into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_csv(csv_url)\n",
        "    print(f\"‚úÖ Successfully loaded {len(df)} total tweets.\")\n",
        "\n",
        "    # --- CRITICAL STEP FOR SPEED ---\n",
        "    # Create a smaller sample to work with. We'll use 100 for this run.\n",
        "    sample_size = 100\n",
        "    df_sample = df.head(sample_size)\n",
        "    print(f\"üî• Created a sample of {len(df_sample)} tweets to process.\")\n",
        "\n",
        "    # Display the first 5 rows of our sample to see what we're working with\n",
        "    print(\"\\n--- Data Preview ---\")\n",
        "    print(df_sample.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"üö® Error loading data from URL: {e}\")"
      ],
      "metadata": {
        "id": "fW72nm-yhZbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.5: The Classification Cleaning Function\n",
        "import re\n",
        "\n",
        "# A list of our official, clean categories\n",
        "VALID_CATEGORIES = [\n",
        "    'Urgent Plea for Help',\n",
        "    'Infrastructure Damage Report',\n",
        "    'Informational News/Update',\n",
        "    'Irrelevant/Noise'\n",
        "]\n",
        "\n",
        "def clean_classification(raw_text):\n",
        "    \"\"\"\n",
        "    This function takes the raw output from the LLM and cleans it.\n",
        "    It searches for one of the valid categories within the text.\n",
        "    \"\"\"\n",
        "    for category in VALID_CATEGORIES:\n",
        "        # Search for the category, ignoring case and leading/trailing junk\n",
        "        if re.search(category, raw_text, re.IGNORECASE):\n",
        "            return category  # Return the clean, official category name\n",
        "\n",
        "    return 'Irrelevant/Noise' # If no valid category is found, default to Noise"
      ],
      "metadata": {
        "id": "Lh4qqhkQyKSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Part 1 - Data Classification (UPDATED with Cleaner)\n",
        "\n",
        "# Create an empty list to store our classification results\n",
        "classification_results = []\n",
        "\n",
        "# (The prompt_template remains the same)\n",
        "prompt_template = \"\"\"\n",
        "Analyze the tweet below and classify it into ONE of the following categories:\n",
        "- 'Urgent Plea for Help'\n",
        "- 'Infrastructure Damage Report'\n",
        "- 'Informational News/Update'\n",
        "- 'Irrelevant/Noise'\n",
        "\n",
        "Provide only the category name as your answer.\n",
        "\n",
        "Tweet: \"{tweet_text}\"\n",
        "\n",
        "Classification:\n",
        "\"\"\"\n",
        "\n",
        "# Use tqdm for a progress bar!\n",
        "for index, row in tqdm(df_sample.iterrows(), total=df_sample.shape[0], desc=\"Classifying Tweets\"):\n",
        "    tweet_text = row['text']\n",
        "    final_prompt = prompt_template.format(tweet_text=tweet_text)\n",
        "\n",
        "    try:\n",
        "        response = llm.invoke(final_prompt)\n",
        "\n",
        "        # --- THIS IS THE KEY CHANGE ---\n",
        "        # Use our function to clean the messy output\n",
        "        classification = clean_classification(response)\n",
        "\n",
        "        classification_results.append({\n",
        "            'tweet_id': row['id'],\n",
        "            'tweet_text': tweet_text,\n",
        "            'classification': classification # Now storing the CLEAN classification\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üö® Error classifying tweet {row['id']}: {e}\")\n",
        "        classification_results.append({\n",
        "            'tweet_id': row['id'],\n",
        "            'tweet_text': tweet_text,\n",
        "            'classification': 'ERROR'\n",
        "        })\n",
        "\n",
        "# Convert the results list into a new DataFrame\n",
        "results_df = pd.DataFrame(classification_results)\n",
        "print(\"\\n‚úÖ Classification phase complete with cleaned data.\")"
      ],
      "metadata": {
        "id": "1AYRtaVoiIcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Analyzing the Classification Results\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"--- üìä INSIGHT FROM CLASSIFICATION ---\")\n",
        "print(\"This breakdown shows us where to focus our attention.\\n\")\n",
        "\n",
        "# Get the counts of each category\n",
        "classification_counts = results_df['classification'].value_counts()\n",
        "print(classification_counts)\n",
        "\n",
        "# --- Visualization ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=classification_counts.index, y=classification_counts.values, palette='viridis')\n",
        "plt.title('Distribution of Disaster Tweet Classifications', fontsize=16)\n",
        "plt.ylabel('Number of Tweets', fontsize=12)\n",
        "plt.xlabel('Classification Category', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aQhoatcnjTN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Part 2 - Data Summarization\n",
        "# Our goal: Distill the most critical classified data into a high-level summary.\n",
        "\n",
        "print(\"\\n\\n--- üìù INITIATING SUMMARIZATION PHASE ---\")\n",
        "\n",
        "# First, isolate the tweets that are most important\n",
        "# We'll focus on 'Urgent Plea for Help'\n",
        "urgent_pleas_df = results_df[results_df['classification'] == 'Urgent Plea for Help']\n",
        "\n",
        "# Check if we have any urgent pleas to summarize\n",
        "if not urgent_pleas_df.empty:\n",
        "    print(f\"Found {len(urgent_pleas_df)} urgent pleas. Compiling for summary...\")\n",
        "\n",
        "    # Combine all the urgent tweets into a single block of text\n",
        "    all_pleas_text = \"\\n\".join(\"- \" + tweet for tweet in urgent_pleas_df['tweet_text'])\n",
        "\n",
        "    # Create a powerful summarization prompt\n",
        "    summarization_prompt = f\"\"\"\n",
        "You are an expert emergency services analyst. Your job is to provide a quick intelligence briefing.\n",
        "Read the following collection of urgent pleas for help from a disaster zone and provide a concise summary in 3-4 bullet points.\n",
        "Focus on identifying recurring themes, types of emergencies (e.g., trapped people, fires, injuries), and any specific locations mentioned.\n",
        "\n",
        "Urgent Tweets:\n",
        "{all_pleas_text}\n",
        "\n",
        "Intelligence Briefing:\n",
        "\"\"\"\n",
        "\n",
        "    print(\"\\nSending compiled pleas to IBM Granite for summarization...\")\n",
        "    try:\n",
        "        # Get the summary from the LLM\n",
        "        summary_response = llm.invoke(summarization_prompt)\n",
        "\n",
        "        # --- üö® FINAL KEY INSIGHT üö® ---\n",
        "        print(\"\\n\\n--- EXECUTIVE SUMMARY OF URGENT PLEAS ---\")\n",
        "        print(summary_response)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üö® Error during summarization: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo tweets were classified as 'Urgent Plea for Help' in this sample. Skipping summarization.\")"
      ],
      "metadata": {
        "id": "wFF-b03bjXPR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
